{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ade92088",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "from sklearn.decomposition import PCA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6a3fe20",
   "metadata": {},
   "outputs": [],
   "source": [
    "ingredient_to_category = {\n",
    "    # Nuts\n",
    "    \"peanuts\": \"Nuts\",\n",
    "    \"cashew\": \"Nuts\",\n",
    "    \"chestnuts\": \"Nuts\",\n",
    "    \"pistachios\": \"Nuts\",\n",
    "    \"almond\": \"Nuts\",\n",
    "    \"hazelnut\": \"Nuts\",\n",
    "    \"walnuts\": \"Nuts\",\n",
    "    \"pecans\": \"Nuts\",\n",
    "    \"brazil_nut\": \"Nuts\",\n",
    "    \"pili_nut\": \"Nuts\",\n",
    "    \n",
    "    # Spices\n",
    "    \"cumin\": \"Spices\",\n",
    "    \"star_anise\": \"Spices\",\n",
    "    \"nutmeg\": \"Spices\",\n",
    "    \"cloves\": \"Spices\",\n",
    "    \"ginger\": \"Spices\",\n",
    "    \"allspice\": \"Spices\",\n",
    "    \"chervil\": \"Spices\",\n",
    "    \"mustard\": \"Spices\",\n",
    "    \"cinnamon\": \"Spices\",\n",
    "    \"saffron\": \"Spices\",\n",
    "    \n",
    "    # Herbs\n",
    "    \"angelica\": \"Herbs\",\n",
    "    \"garlic\": \"Herbs\",\n",
    "    \"chives\": \"Herbs\",\n",
    "    \"turnip\": \"Herbs\",\n",
    "    \"dill\": \"Herbs\",\n",
    "    \"mugwort\": \"Herbs\",\n",
    "    \"chamomile\": \"Herbs\",\n",
    "    \"coriander\": \"Herbs\",\n",
    "    \"oregano\": \"Herbs\",\n",
    "    \"mint\": \"Herbs\",\n",
    "    \n",
    "    # Fruits\n",
    "    \"kiwi\": \"Fruits\",\n",
    "    \"pineapple\": \"Fruits\",\n",
    "    \"banana\": \"Fruits\",\n",
    "    \"lemon\": \"Fruits\",\n",
    "    \"mandarin_orange\": \"Fruits\",\n",
    "    \"strawberry\": \"Fruits\",\n",
    "    \"apple\": \"Fruits\",\n",
    "    \"mango\": \"Fruits\",\n",
    "    \"peach\": \"Fruits\",\n",
    "    \"pear\": \"Fruits\",\n",
    "    \n",
    "    # Vegetables\n",
    "    \"cauliflower\": \"Vegetables\",\n",
    "    \"brussel_sprouts\": \"Vegetables\",\n",
    "    \"broccoli\": \"Vegetables\",\n",
    "    \"sweet_potato\": \"Vegetables\",\n",
    "    \"asparagus\": \"Vegetables\",\n",
    "    \"avocado\": \"Vegetables\",\n",
    "    \"radish\": \"Vegetables\",\n",
    "    \"tomato\": \"Vegetables\",\n",
    "    \"potato\": \"Vegetables\",\n",
    "    \"cabbage\": \"Vegetables\",\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "81c68231",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = defaultdict(list)\n",
    "testing_data = defaultdict(list)\n",
    "real_testing_data = defaultdict(list)\n",
    "\n",
    "training_path = \"/home/dewei/workspace/smell-net/training\"\n",
    "testing_path = \"/home/dewei/workspace/smell-net/testing\"\n",
    "# real_testing_path = \"/home/dewei/workspace/smell-net/processed_real_time_testing\"\n",
    "max_len = 0  # Track minimum length across all series\n",
    "num_data = 0\n",
    "\n",
    "# Walk through the training directory\n",
    "for folder_name in os.listdir(training_path):\n",
    "    folder_path = os.path.join(training_path, folder_name)\n",
    "    \n",
    "    if os.path.isdir(folder_path):  # Make sure it's a folder\n",
    "        for filename in os.listdir(folder_path):\n",
    "            if filename.endswith(\".csv\"):\n",
    "                cur_path = os.path.join(folder_path, filename)\n",
    "                df = pd.read_csv(cur_path)\n",
    "                training_data[folder_name].append(df)\n",
    "                max_len = max(max_len, df.shape[0])  # Update minimum length\n",
    "                num_data += df.shape[0]\n",
    "\n",
    "for folder_name in os.listdir(testing_path):\n",
    "    folder_path = os.path.join(testing_path, folder_name)\n",
    "    \n",
    "    if os.path.isdir(folder_path):  # Make sure it's a folder\n",
    "        for filename in os.listdir(folder_path):\n",
    "            if filename.endswith(\".csv\"):\n",
    "                cur_path = os.path.join(folder_path, filename)\n",
    "                df = pd.read_csv(cur_path)\n",
    "                testing_data[folder_name].append(df)\n",
    "                max_len = max(max_len, df.shape[0])  # Update minimum length\n",
    "                num_data += df.shape[0]\n",
    "\n",
    "# for folder_name in os.listdir(real_testing_path):\n",
    "#     folder_path = os.path.join(real_testing_path, folder_name)\n",
    "    \n",
    "#     if os.path.isdir(folder_path):  # Make sure it's a folder\n",
    "#         for filename in os.listdir(folder_path):\n",
    "#             if filename.endswith(\".csv\"):\n",
    "#                 cur_path = os.path.join(folder_path, filename)\n",
    "#                 df = pd.read_csv(cur_path)\n",
    "#                 real_testing_data[folder_name].append(df)\n",
    "#                 min_len = min(min_len, df.shape[0])  # Update minimum length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e3905616",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180718\n"
     ]
    }
   ],
   "source": [
    "print(num_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e858b553",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       ingredient    category\n",
      "0          ginger      Spices\n",
      "2976   brazil_nut        Nuts\n",
      "5983      walnuts        Nuts\n",
      "9263      oregano       Herbs\n",
      "12216     cabbage  Vegetables\n"
     ]
    }
   ],
   "source": [
    "aggregated_training = []\n",
    "aggregated_testing = []\n",
    "\n",
    "# Aggregate training data\n",
    "for ingredient, dfs in training_data.items():\n",
    "    for i, df in enumerate(dfs):\n",
    "        df = df.copy()  # Safe copy\n",
    "        df['ingredient'] = ingredient\n",
    "        df['file_id'] = f\"{ingredient}_train_{i}\"\n",
    "        df['time_step'] = range(len(df))\n",
    "        aggregated_training.append(df)\n",
    "\n",
    "# Aggregate testing data\n",
    "for ingredient, dfs in testing_data.items():\n",
    "    for i, df in enumerate(dfs):\n",
    "        df = df.copy()\n",
    "        df['ingredient'] = ingredient\n",
    "        df['file_id'] = f\"{ingredient}_test_{i}\"\n",
    "        df['time_step'] = range(len(df))\n",
    "        aggregated_testing.append(df)\n",
    "\n",
    "# Concatenate into final DataFrames\n",
    "aggregated_training = pd.concat(aggregated_training, ignore_index=True)\n",
    "aggregated_testing = pd.concat(aggregated_testing, ignore_index=True)\n",
    "\n",
    "# Map the ingredient to category\n",
    "aggregated_training['category'] = aggregated_training['ingredient'].map(ingredient_to_category)\n",
    "aggregated_testing['category'] = aggregated_testing['ingredient'].map(ingredient_to_category)\n",
    "\n",
    "# Check a few examples\n",
    "print(aggregated_training[['ingredient', 'category']].drop_duplicates().head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a90c70ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Summary:\n",
      "              NO2      C2H5OH         VOC          CO     Alcohol         LPG  \\\n",
      "count  150711.000  150711.000  150711.000  150711.000  150711.000  150711.000   \n",
      "mean       97.795     138.328     195.943     792.938       3.407      30.333   \n",
      "std       118.680     143.402     196.188      61.667       3.279      38.286   \n",
      "min        13.000      39.000      26.000     705.000       0.000       2.000   \n",
      "25%        35.000      65.000      73.000     750.000       1.000      14.000   \n",
      "50%        46.000      77.000     106.000     776.000       2.000      23.000   \n",
      "75%       105.000     140.000     232.500     820.000       5.000      32.000   \n",
      "max       753.000     863.000     953.000    1006.000      42.000     507.000   \n",
      "\n",
      "            Benzene  Temperature    Pressure    Humidity  Gas_Resistance  \\\n",
      "count  1.507110e+05   150711.000  150711.000  150711.000      150711.000   \n",
      "mean   1.392784e+09       27.135     949.109      46.610         220.891   \n",
      "std    2.010508e+09        3.277     131.953      27.904         179.991   \n",
      "min    0.000000e+00       24.350     688.600      20.150           0.000   \n",
      "25%    0.000000e+00       25.420    1004.520      27.290          40.650   \n",
      "50%    0.000000e+00       25.600    1013.990      38.670         220.890   \n",
      "75%    4.294967e+09       25.860    1020.450      45.860         375.420   \n",
      "max    4.294967e+09       33.590    1024.190     100.000         704.960   \n",
      "\n",
      "         Altitude  \n",
      "count  150711.000  \n",
      "mean      654.290  \n",
      "std      1274.261  \n",
      "min       -59.470  \n",
      "25%       -28.580  \n",
      "50%        25.000  \n",
      "75%       104.040  \n",
      "max      3170.540  \n",
      "\n",
      "Testing Data Summary:\n",
      "             NO2     C2H5OH        VOC         CO    Alcohol        LPG  \\\n",
      "count  30007.000  29423.000  30007.000  30007.000  30007.000  30007.000   \n",
      "mean      98.569    134.077    196.976    794.024      3.461     32.927   \n",
      "std      121.301    140.970    200.262     61.792      3.114     45.799   \n",
      "min       15.000     41.000     26.000    710.000      0.000      3.000   \n",
      "25%       35.000     65.000     72.000    751.000      1.000     14.500   \n",
      "50%       45.000     73.000     96.000    775.000      2.000     23.000   \n",
      "75%      103.000    135.000    237.000    825.000      6.000     34.000   \n",
      "max      775.000    850.000    947.000   1004.000     30.000    444.000   \n",
      "\n",
      "            Benzene  Temperature   Pressure   Humidity  Gas_Resistance  \\\n",
      "count  3.000700e+04    30007.000  30007.000  30007.000       30007.000   \n",
      "mean   1.376359e+09       27.145    948.171     46.706         221.393   \n",
      "std    2.004292e+09        3.304    132.703     28.089         174.715   \n",
      "min    0.000000e+00       24.370    688.600     20.320           0.000   \n",
      "25%    0.000000e+00       25.360   1004.600     27.220          33.000   \n",
      "50%    0.000000e+00       25.630   1014.260     38.480         225.870   \n",
      "75%    4.294967e+09       25.920   1020.640     46.095         365.860   \n",
      "max    4.294967e+09       33.590   1023.490    100.000         685.540   \n",
      "\n",
      "        Altitude  \n",
      "count  30007.000  \n",
      "mean     663.427  \n",
      "std     1281.484  \n",
      "min      -53.700  \n",
      "25%      -30.150  \n",
      "50%       22.750  \n",
      "75%      103.370  \n",
      "max     3170.540  \n"
     ]
    }
   ],
   "source": [
    "# Select only the sensor columns (exclude ingredient, file_id, time_step)\n",
    "sensor_columns = [\n",
    "    'NO2', 'C2H5OH', 'VOC', 'CO', 'Alcohol', 'LPG', 'Benzene',\n",
    "    'Temperature', 'Pressure', 'Humidity', 'Gas_Resistance', 'Altitude'\n",
    "]\n",
    "\n",
    "# 1. Overall summary (across all training samples)\n",
    "training_summary = aggregated_training[sensor_columns].describe().round(3)\n",
    "testing_summary = aggregated_testing[sensor_columns].describe().round(3)\n",
    "\n",
    "print(\"Training Data Summary:\")\n",
    "print(training_summary)\n",
    "\n",
    "print(\"\\nTesting Data Summary:\")\n",
    "print(testing_summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5331e14e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Group by ingredient and compute mean and std for each feature\n",
    "training_grouped_stats = aggregated_training.groupby('ingredient')[sensor_columns].agg(['mean', 'std']).round(3)\n",
    "testing_grouped_stats = aggregated_testing.groupby('ingredient')[sensor_columns].agg(['mean', 'std']).round(3)\n",
    "\n",
    "print(\"Training Data Grouped Statistics (per ingredient):\")\n",
    "print(training_grouped_stats)\n",
    "\n",
    "print(\"\\nTesting Data Grouped Statistics (per ingredient):\")\n",
    "print(testing_grouped_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b553688e",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_summary.to_csv(\"/home/dewei/workspace/SmellNet/data_stats/training_summary.csv\")\n",
    "testing_summary.to_csv(\"/home/dewei/workspace/SmellNet/data_stats/testing_summary.csv\")\n",
    "training_grouped_stats.to_csv(\"/home/dewei/workspace/SmellNet/data_stats/training_grouped_stats.csv\")\n",
    "testing_grouped_stats.to_csv(\"/home/dewei/workspace/SmellNet/data_stats/testing_grouped_stats.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3cb2d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set a style for prettier plots\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "# Plot distributions for training data\n",
    "for feature in sensor_columns:\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    sns.histplot(aggregated_training[feature], kde=True, bins=50, color='skyblue')\n",
    "    plt.title(f\"Training Data: Distribution of {feature}\")\n",
    "    plt.xlabel(feature)\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5759f9bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in sensor_columns:\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    sns.kdeplot(aggregated_training[feature], label=\"Training\", fill=True, alpha=0.5)\n",
    "    sns.kdeplot(aggregated_testing[feature], label=\"Testing\", fill=True, alpha=0.5)\n",
    "    plt.title(f\"Distribution of {feature}: Training vs Testing\")\n",
    "    plt.xlabel(feature)\n",
    "    plt.ylabel(\"Density\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6302eb06",
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in sensor_columns:\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    sns.kdeplot(aggregated_training[feature], label=\"Training\", fill=True, alpha=0.5)\n",
    "    sns.kdeplot(aggregated_testing[feature], label=\"Testing\", fill=True, alpha=0.5)\n",
    "    plt.title(f\"Distribution of {feature}: Training vs Testing\")\n",
    "    plt.xlabel(feature)\n",
    "    plt.ylabel(\"Density\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"/Users/derre/Documents/workspace/SmellNet/data_stats/feature_distribution_train_vs_test_{feature}.png\", dpi=300)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d8e43aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_category_stats = aggregated_training.groupby('category')[sensor_columns].agg(['mean', 'std']).round(3)\n",
    "testing_category_stats = aggregated_testing.groupby('category')[sensor_columns].agg(['mean', 'std']).round(3)\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "for feature in sensor_columns:\n",
    "    # Prepare data\n",
    "    means = training_category_stats[feature]['mean']\n",
    "    stds = training_category_stats[feature]['std']\n",
    "    \n",
    "    categories = means.index.tolist()\n",
    "    mean_values = means.values\n",
    "    std_values = stds.values\n",
    "    \n",
    "    # Create plot\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.barplot(\n",
    "        x=categories, \n",
    "        y=mean_values, \n",
    "        palette=\"muted\"\n",
    "    )\n",
    "\n",
    "    # Add error bars manually\n",
    "    plt.errorbar(\n",
    "        x=range(len(categories)), \n",
    "        y=mean_values, \n",
    "        yerr=std_values, \n",
    "        fmt='none', \n",
    "        c='black', \n",
    "        capsize=5\n",
    "    )\n",
    "\n",
    "    plt.title(f\"Mean {feature} per Category (Training Data)\", fontsize=16)\n",
    "    plt.xlabel(\"Category\", fontsize=14)\n",
    "    plt.ylabel(f\"Mean {feature} Value\", fontsize=14)\n",
    "    plt.xticks(rotation=45, ha=\"right\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"/Users/derre/Documents/workspace/smell-net/data_stats/feature_distributions_category/{feature}_mean_per_category.png\", dpi=300)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "027ef795",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "for feature in sensor_columns:\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    # Plot one KDE per category\n",
    "    for category in aggregated_training['category'].dropna().unique():\n",
    "        subset = aggregated_training[aggregated_training['category'] == category]\n",
    "        sns.kdeplot(\n",
    "            subset[feature], \n",
    "            label=category, \n",
    "            fill=True, \n",
    "            alpha=0.3\n",
    "        )\n",
    "    \n",
    "    plt.title(f\"Training Data: {feature} Distribution by Category\", fontsize=16)\n",
    "    plt.xlabel(feature, fontsize=14)\n",
    "    plt.ylabel(\"Density\", fontsize=14)\n",
    "    plt.legend(title=\"Category\", fontsize=10)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"/home/dewei/workspace/smell-net/data_stats/feature_distributions_category/{feature}_kde_by_category.png\", dpi=300)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aeaddf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_files = [\"angelica_test_0\", \"mint_test_0\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "24d81ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_files = [\"angelica_test_0\", \"mint_test_0\"]\n",
    "plot_columns = [\"NO2\"]\n",
    "\n",
    "for file_id in sampled_files:\n",
    "    df = aggregated_testing[aggregated_testing['file_id'] == file_id].copy()\n",
    "\n",
    "    for col in plot_columns:\n",
    "        # Wider figure for better aspect ratio\n",
    "        fig, ax = plt.subplots(figsize=(8, 4))\n",
    "\n",
    "        ax.plot(df['time_step'], df[col], color='steelblue')\n",
    "\n",
    "        # Titles and labels\n",
    "        ax.set_title(f\"NO2 over Time\", fontsize=22, fontweight='bold')\n",
    "        ax.set_xlabel(\"Time Step\", fontsize=20)\n",
    "        ax.set_ylabel(col, fontsize=20)\n",
    "        ax.tick_params(axis='both', which='major', labelsize=16)\n",
    "        ax.grid(True)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f\"/home/dewei/workspace/smell-net/data_stats/time_series_analysis/{file_id}_{col}_timeseries.png\", dpi=300)\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "61590319",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Compute correlation matrix\n",
    "correlation_matrix = aggregated_training[sensor_columns].corr()\n",
    "\n",
    "# 2. Plot the correlation matrix (larger and bolder)\n",
    "plt.figure(figsize=(16, 14))  # Larger figure\n",
    "\n",
    "sns.heatmap(\n",
    "    correlation_matrix,\n",
    "    annot=True,\n",
    "    fmt=\".2f\",\n",
    "    cmap=\"coolwarm\",\n",
    "    vmin=-1, vmax=1,\n",
    "    square=True,\n",
    "    cbar_kws={\"shrink\": 0.75},\n",
    "    annot_kws={\"size\": 20}  # Larger annotation text\n",
    ")\n",
    "\n",
    "# Bold and large title\n",
    "plt.title(\"Sensor Feature Correlation Matrix\", fontsize=30, fontweight='bold')\n",
    "\n",
    "# Bigger and readable tick labels\n",
    "plt.xticks(rotation=45, ha='right', fontsize=25)\n",
    "plt.yticks(rotation=45, fontsize=25)\n",
    "\n",
    "plt.tight_layout(pad=2.0)\n",
    "plt.savefig(\"/home/dewei/workspace/SmellNet/data_stats/feature_correlation.png\", dpi=300)\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "68176c62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained variance ratios: [0.39145314 0.34491947]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# === Prepare Sensor Data ===\n",
    "X_raw = aggregated_training[sensor_columns]\n",
    "y_category = aggregated_training['category']\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_raw)\n",
    "\n",
    "# === PCA Transformation ===\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "explained_var = pca.explained_variance_ratio_\n",
    "print(f\"Explained variance ratios: {explained_var}\")\n",
    "\n",
    "# === Create DataFrame for Visualization ===\n",
    "pca_df = pd.DataFrame({\n",
    "    'PC1': X_pca[:, 0],\n",
    "    'PC2': X_pca[:, 1],\n",
    "    'Category': y_category\n",
    "})\n",
    "\n",
    "# === Plotting ===\n",
    "sns.set(style=\"whitegrid\", context=\"notebook\")  # 'notebook' = larger fonts\n",
    "custom_palette = [\"#1f77b4\", \"#ff7f0e\", \"#2ca02c\", \"#d62728\", \"#9467bd\"]\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "plot = sns.scatterplot(\n",
    "    data=pca_df,\n",
    "    x='PC1', y='PC2',\n",
    "    hue='Category',\n",
    "    palette=custom_palette,\n",
    "    s=8,             # larger dots\n",
    "    alpha=0.6,\n",
    "    linewidth=0\n",
    ")\n",
    "\n",
    "# Axis labels with explained variance\n",
    "plt.xlabel(f\"PC1 ({explained_var[0]*100:.1f}% variance)\", fontsize=25)\n",
    "plt.ylabel(f\"PC2 ({explained_var[1]*100:.1f}% variance)\", fontsize=25)\n",
    "plt.title(\"PCA of Sensor Data\", fontsize=33, fontweight='bold')\n",
    "\n",
    "# Tick label fonts\n",
    "plt.xticks(fontsize=18)\n",
    "plt.yticks(fontsize=18)\n",
    "\n",
    "# Legend styling\n",
    "plt.legend(\n",
    "    title=\"Ingredient Category\",\n",
    "    title_fontsize=25,\n",
    "    fontsize=25,\n",
    "    bbox_to_anchor=(1.05, 1),\n",
    "    loc='upper left',\n",
    "    handletextpad=0.4,\n",
    "    borderaxespad=0.2,\n",
    "    labelspacing=0.8,\n",
    "    handlelength=2.5,\n",
    "    markerscale=5   # Increase dot size in legend\n",
    ")\n",
    "\n",
    "# Save figure\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"/home/dewei/workspace/smell-net/data_stats/PCA_sensor_data_category.png\", dpi=300)\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b0676295",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Contributions:\n",
      "                     PC1       PC2  Magnitude\n",
      "C2H5OH         -0.001529  0.463920   0.463922\n",
      "VOC             0.002555  0.461955   0.461962\n",
      "NO2            -0.000228  0.457690   0.457690\n",
      "Pressure        0.452413  0.009620   0.452515\n",
      "Altitude       -0.452181 -0.010113   0.452294\n",
      "Humidity       -0.452143  0.001751   0.452146\n",
      "Temperature    -0.449991 -0.010153   0.450106\n",
      "Gas_Resistance  0.333414 -0.241611   0.411753\n",
      "CO              0.017569  0.396739   0.397128\n",
      "Benzene         0.056469  0.339980   0.344638\n",
      "Alcohol         0.229455  0.100311   0.250423\n",
      "LPG             0.128875  0.142016   0.191774\n"
     ]
    }
   ],
   "source": [
    "# Get feature contributions (loadings) for PC1 and PC2\n",
    "loadings = pd.DataFrame(pca.components_.T,  # transpose to get features as rows\n",
    "                        columns=['PC1', 'PC2'],\n",
    "                        index=sensor_columns)\n",
    "\n",
    "# Compute magnitude of contribution (Euclidean norm)\n",
    "loadings['Magnitude'] = (loadings[['PC1', 'PC2']]**2).sum(axis=1)**0.5\n",
    "\n",
    "# Sort features by magnitude\n",
    "top_features = loadings.sort_values('Magnitude', ascending=False)\n",
    "print(\"Feature Contributions:\")\n",
    "print(top_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4bb42047",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Seaborn style for large, clear visuals\n",
    "sns.set(style=\"whitegrid\", context=\"notebook\", font_scale=1.4)\n",
    "\n",
    "# Output directory\n",
    "output_dir = \"/home/dewei/workspace/smell-net/data_stats/pca_by_category_colored\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Iterate over each category\n",
    "for category in aggregated_training['category'].unique():\n",
    "    group_df = aggregated_training[aggregated_training['category'] == category]\n",
    "    X = group_df[sensor_columns]\n",
    "\n",
    "    # Standardize\n",
    "    X_scaled = StandardScaler().fit_transform(X)\n",
    "\n",
    "    # PCA\n",
    "    pca = PCA(n_components=2)\n",
    "    X_pca = pca.fit_transform(X_scaled)\n",
    "    explained_var = pca.explained_variance_ratio_\n",
    "\n",
    "    # Build PCA DataFrame\n",
    "    pca_df = pd.DataFrame({\n",
    "        'PC1': X_pca[:, 0],\n",
    "        'PC2': X_pca[:, 1],\n",
    "        'Ingredient': group_df['ingredient'].values\n",
    "    })\n",
    "\n",
    "    # Create figure\n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "    # Scatter plot with larger, semi-transparent dots\n",
    "    sns.scatterplot(\n",
    "        data=pca_df,\n",
    "        x='PC1', y='PC2',\n",
    "        hue='Ingredient',\n",
    "        palette='tab20',\n",
    "        s=8,\n",
    "        alpha=0.7,\n",
    "        linewidth=0,\n",
    "        ax=ax\n",
    "    )\n",
    "\n",
    "    # Axis and title styling\n",
    "    ax.set_title(f\"{category} PCA\", fontsize=33, fontweight='bold')\n",
    "    ax.set_xlabel(f\"PC1 ({explained_var[0]*100:.1f}% variance)\", fontsize=25)\n",
    "    ax.set_ylabel(f\"PC2 ({explained_var[1]*100:.1f}% variance)\", fontsize=25)\n",
    "    ax.tick_params(axis='both', labelsize=16)\n",
    "\n",
    "    # Adjust legend: bold text and bigger markers\n",
    "    plt.legend(\n",
    "        title=\"Ingredient\",\n",
    "        title_fontsize=25,\n",
    "        fontsize=25,\n",
    "        bbox_to_anchor=(1.05, 1),\n",
    "        loc='upper left',\n",
    "        handletextpad=0.4,\n",
    "        borderaxespad=0.2,\n",
    "        labelspacing=0.8,\n",
    "        handlelength=2.5,\n",
    "        markerscale=5   # Increase dot size in legend\n",
    "    )\n",
    "\n",
    "    # Save plot\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{output_dir}/PCA_{category.replace(' ', '_')}_by_ingredient.png\", dpi=300)\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd6b7162",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set up the grid for subplots\n",
    "categories = aggregated_training['category'].unique()\n",
    "n_categories = len(categories)\n",
    "\n",
    "n_cols = 5  # You can change this\n",
    "n_rows = (n_categories + n_cols - 1) // n_cols  # Ceiling division\n",
    "\n",
    "plt.figure(figsize=(4 * n_cols, 4 * n_rows))\n",
    "\n",
    "for i, category in enumerate(categories):\n",
    "    plt.subplot(n_rows, n_cols, i + 1)\n",
    "    \n",
    "    # Select data for this category\n",
    "    group_df = aggregated_training[aggregated_training['category'] == category]\n",
    "    X = group_df[sensor_columns]\n",
    "    \n",
    "    # Standardize\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    \n",
    "    # PCA\n",
    "    pca = PCA(n_components=2)\n",
    "    X_pca = pca.fit_transform(X_scaled)\n",
    "    explained = pca.explained_variance_ratio_\n",
    "    \n",
    "    # Scatter plot\n",
    "    plt.scatter(X_pca[:, 0], X_pca[:, 1], s=5, alpha=0.6)\n",
    "    \n",
    "    # Title with explained variance\n",
    "    plt.title(f\"{category}\\n({explained[0]*100:.1f}%, {explained[1]*100:.1f}%)\", fontsize=10)\n",
    "    \n",
    "    # Remove ticks but keep axis labels\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.xlabel('PC1', fontsize=8)\n",
    "    plt.ylabel('PC2', fontsize=8)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "976827df",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_category_rows = aggregated_training[aggregated_training['category'].isna()]\n",
    "\n",
    "# Display them\n",
    "print(missing_category_rows)\n",
    "\n",
    "# Optional: check how many\n",
    "print(f\"Number of rows with missing category: {len(missing_category_rows)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1a4896e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['Cashew', 'Peanuts', 'Pecans', 'Walnuts', 'Pili Nut']\n",
    "cos_similarities = [0.7176, 0.5056, 0.4912, 0.3945, 0.3466]\n",
    "colors = ['midnightblue'] + ['royalblue'] * 4\n",
    "\n",
    "plt.figure(figsize=(6, 4.5))  # Match aspect ratio to 4:3\n",
    "\n",
    "bars = plt.bar(labels, cos_similarities, color=colors, edgecolor='black', linewidth=1.2)\n",
    "\n",
    "for bar, sim in zip(bars, cos_similarities):\n",
    "    plt.text(bar.get_x() + bar.get_width() / 2, bar.get_height() + 0.015, \n",
    "             f\"{sim:.2f}\", ha='center', va='bottom', fontsize=14)\n",
    "\n",
    "plt.title(\"Top-5 Predicted Ingredients\", fontsize=20, fontweight='bold')\n",
    "plt.ylabel(\"Cosine Similarity\", fontsize=20)\n",
    "plt.xticks(fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "plt.ylim(0, max(cos_similarities) + 0.1)\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.5)\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(\"model_predictions.png\", dpi=300)\n",
    "plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
