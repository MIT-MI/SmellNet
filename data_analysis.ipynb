{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ade92088",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "from sklearn.decomposition import PCA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a3fe20",
   "metadata": {},
   "outputs": [],
   "source": [
    "ingredient_to_category = {\n",
    "    # Nuts\n",
    "    \"peanuts\": \"Nuts\",\n",
    "    \"cashew\": \"Nuts\",\n",
    "    \"chestnuts\": \"Nuts\",\n",
    "    \"pistachios\": \"Nuts\",\n",
    "    \"almond\": \"Nuts\",\n",
    "    \"hazelnut\": \"Nuts\",\n",
    "    \"walnuts\": \"Nuts\",\n",
    "    \"pecans\": \"Nuts\",\n",
    "    \"brazil_nut\": \"Nuts\",\n",
    "    \"pili_nut\": \"Nuts\",\n",
    "    \n",
    "    # Spices\n",
    "    \"cumin\": \"Spices\",\n",
    "    \"star_anise\": \"Spices\",\n",
    "    \"nutmeg\": \"Spices\",\n",
    "    \"cloves\": \"Spices\",\n",
    "    \"ginger\": \"Spices\",\n",
    "    \"allspice\": \"Spices\",\n",
    "    \"chervil\": \"Spices\",\n",
    "    \"mustard\": \"Spices\",\n",
    "    \"cinnamon\": \"Spices\",\n",
    "    \"saffron\": \"Spices\",\n",
    "    \n",
    "    # Herbs\n",
    "    \"angelica\": \"Herbs\",\n",
    "    \"garlic\": \"Herbs\",\n",
    "    \"chives\": \"Herbs\",\n",
    "    \"turnip\": \"Herbs\",\n",
    "    \"dill\": \"Herbs\",\n",
    "    \"mugwort\": \"Herbs\",\n",
    "    \"chamomile\": \"Herbs\",\n",
    "    \"coriander\": \"Herbs\",\n",
    "    \"oregano\": \"Herbs\",\n",
    "    \"mint\": \"Herbs\",\n",
    "    \n",
    "    # Fruits\n",
    "    \"kiwi\": \"Fruits\",\n",
    "    \"pineapple\": \"Fruits\",\n",
    "    \"banana\": \"Fruits\",\n",
    "    \"lemon\": \"Fruits\",\n",
    "    \"mandarin_orange\": \"Fruits\",\n",
    "    \"strawberry\": \"Fruits\",\n",
    "    \"apple\": \"Fruits\",\n",
    "    \"mango\": \"Fruits\",\n",
    "    \"peach\": \"Fruits\",\n",
    "    \"pear\": \"Fruits\",\n",
    "    \n",
    "    # Vegetables\n",
    "    \"cauliflower\": \"Vegetables\",\n",
    "    \"brussel_sprouts\": \"Vegetables\",\n",
    "    \"broccoli\": \"Vegetables\",\n",
    "    \"sweet_potato\": \"Vegetables\",\n",
    "    \"asparagus\": \"Vegetables\",\n",
    "    \"avocado\": \"Vegetables\",\n",
    "    \"radish\": \"Vegetables\",\n",
    "    \"tomato\": \"Vegetables\",\n",
    "    \"potato\": \"Vegetables\",\n",
    "    \"cabbage\": \"Vegetables\",\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c68231",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = defaultdict(list)\n",
    "testing_data = defaultdict(list)\n",
    "real_testing_data = defaultdict(list)\n",
    "\n",
    "training_path = \"/home/dewei/workspace/smell-net/training\"\n",
    "testing_path = \"/home/dewei/workspace/smell-net/testing\"\n",
    "# real_testing_path = \"/home/dewei/workspace/smell-net/processed_real_time_testing\"\n",
    "max_len = 0  # Track minimum length across all series\n",
    "num_data = 0\n",
    "\n",
    "# Walk through the training directory\n",
    "for folder_name in os.listdir(training_path):\n",
    "    folder_path = os.path.join(training_path, folder_name)\n",
    "    \n",
    "    if os.path.isdir(folder_path):  # Make sure it's a folder\n",
    "        for filename in os.listdir(folder_path):\n",
    "            if filename.endswith(\".csv\"):\n",
    "                cur_path = os.path.join(folder_path, filename)\n",
    "                df = pd.read_csv(cur_path)\n",
    "                training_data[folder_name].append(df)\n",
    "                max_len = max(max_len, df.shape[0])  # Update minimum length\n",
    "                num_data += df.shape[0]\n",
    "\n",
    "for folder_name in os.listdir(testing_path):\n",
    "    folder_path = os.path.join(testing_path, folder_name)\n",
    "    \n",
    "    if os.path.isdir(folder_path):  # Make sure it's a folder\n",
    "        for filename in os.listdir(folder_path):\n",
    "            if filename.endswith(\".csv\"):\n",
    "                cur_path = os.path.join(folder_path, filename)\n",
    "                df = pd.read_csv(cur_path)\n",
    "                testing_data[folder_name].append(df)\n",
    "                max_len = max(max_len, df.shape[0])  # Update minimum length\n",
    "                num_data += df.shape[0]\n",
    "\n",
    "# for folder_name in os.listdir(real_testing_path):\n",
    "#     folder_path = os.path.join(real_testing_path, folder_name)\n",
    "    \n",
    "#     if os.path.isdir(folder_path):  # Make sure it's a folder\n",
    "#         for filename in os.listdir(folder_path):\n",
    "#             if filename.endswith(\".csv\"):\n",
    "#                 cur_path = os.path.join(folder_path, filename)\n",
    "#                 df = pd.read_csv(cur_path)\n",
    "#                 real_testing_data[folder_name].append(df)\n",
    "#                 min_len = min(min_len, df.shape[0])  # Update minimum length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3905616",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(num_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e858b553",
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregated_training = []\n",
    "aggregated_testing = []\n",
    "\n",
    "# Aggregate training data\n",
    "for ingredient, dfs in training_data.items():\n",
    "    for i, df in enumerate(dfs):\n",
    "        df = df.copy()  # Safe copy\n",
    "        df['ingredient'] = ingredient\n",
    "        df['file_id'] = f\"{ingredient}_train_{i}\"\n",
    "        df['time_step'] = range(len(df))\n",
    "        aggregated_training.append(df)\n",
    "\n",
    "# Aggregate testing data\n",
    "for ingredient, dfs in testing_data.items():\n",
    "    for i, df in enumerate(dfs):\n",
    "        df = df.copy()\n",
    "        df['ingredient'] = ingredient\n",
    "        df['file_id'] = f\"{ingredient}_test_{i}\"\n",
    "        df['time_step'] = range(len(df))\n",
    "        aggregated_testing.append(df)\n",
    "\n",
    "# Concatenate into final DataFrames\n",
    "aggregated_training = pd.concat(aggregated_training, ignore_index=True)\n",
    "aggregated_testing = pd.concat(aggregated_testing, ignore_index=True)\n",
    "\n",
    "# Map the ingredient to category\n",
    "aggregated_training['category'] = aggregated_training['ingredient'].map(ingredient_to_category)\n",
    "aggregated_testing['category'] = aggregated_testing['ingredient'].map(ingredient_to_category)\n",
    "\n",
    "# Check a few examples\n",
    "print(aggregated_training[['ingredient', 'category']].drop_duplicates().head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a90c70ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only the sensor columns (exclude ingredient, file_id, time_step)\n",
    "sensor_columns = [\n",
    "    'NO2', 'C2H5OH', 'VOC', 'CO', 'Alcohol', 'LPG', 'Benzene',\n",
    "    'Temperature', 'Pressure', 'Humidity', 'Gas_Resistance', 'Altitude'\n",
    "]\n",
    "\n",
    "# 1. Overall summary (across all training samples)\n",
    "training_summary = aggregated_training[sensor_columns].describe().round(3)\n",
    "testing_summary = aggregated_testing[sensor_columns].describe().round(3)\n",
    "\n",
    "print(\"Training Data Summary:\")\n",
    "print(training_summary)\n",
    "\n",
    "print(\"\\nTesting Data Summary:\")\n",
    "print(testing_summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5331e14e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Group by ingredient and compute mean and std for each feature\n",
    "training_grouped_stats = aggregated_training.groupby('ingredient')[sensor_columns].agg(['mean', 'std']).round(3)\n",
    "testing_grouped_stats = aggregated_testing.groupby('ingredient')[sensor_columns].agg(['mean', 'std']).round(3)\n",
    "\n",
    "print(\"Training Data Grouped Statistics (per ingredient):\")\n",
    "print(training_grouped_stats)\n",
    "\n",
    "print(\"\\nTesting Data Grouped Statistics (per ingredient):\")\n",
    "print(testing_grouped_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b553688e",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_summary.to_csv(\"/home/dewei/workspace/smell-net/data_stats/training_summary.csv\")\n",
    "testing_summary.to_csv(\"/home/dewei/workspace/smell-net/data_stats/testing_summary.csv\")\n",
    "training_grouped_stats.to_csv(\"/home/dewei/workspace/smell-net/data_stats/training_grouped_stats.csv\")\n",
    "testing_grouped_stats.to_csv(\"/home/dewei/workspace/smell-net/data_stats/testing_grouped_stats.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3cb2d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set a style for prettier plots\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "# Plot distributions for training data\n",
    "for feature in sensor_columns:\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    sns.histplot(aggregated_training[feature], kde=True, bins=50, color='skyblue')\n",
    "    plt.title(f\"Training Data: Distribution of {feature}\")\n",
    "    plt.xlabel(feature)\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5759f9bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in sensor_columns:\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    sns.kdeplot(aggregated_training[feature], label=\"Training\", fill=True, alpha=0.5)\n",
    "    sns.kdeplot(aggregated_testing[feature], label=\"Testing\", fill=True, alpha=0.5)\n",
    "    plt.title(f\"Distribution of {feature}: Training vs Testing\")\n",
    "    plt.xlabel(feature)\n",
    "    plt.ylabel(\"Density\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6302eb06",
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in sensor_columns:\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    sns.kdeplot(aggregated_training[feature], label=\"Training\", fill=True, alpha=0.5)\n",
    "    sns.kdeplot(aggregated_testing[feature], label=\"Testing\", fill=True, alpha=0.5)\n",
    "    plt.title(f\"Distribution of {feature}: Training vs Testing\")\n",
    "    plt.xlabel(feature)\n",
    "    plt.ylabel(\"Density\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"/Users/derre/Documents/workspace/smell-net/data_stats/feature_distribution_train_vs_test_{feature}.png\", dpi=300)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d8e43aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_category_stats = aggregated_training.groupby('category')[sensor_columns].agg(['mean', 'std']).round(3)\n",
    "testing_category_stats = aggregated_testing.groupby('category')[sensor_columns].agg(['mean', 'std']).round(3)\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "for feature in sensor_columns:\n",
    "    # Prepare data\n",
    "    means = training_category_stats[feature]['mean']\n",
    "    stds = training_category_stats[feature]['std']\n",
    "    \n",
    "    categories = means.index.tolist()\n",
    "    mean_values = means.values\n",
    "    std_values = stds.values\n",
    "    \n",
    "    # Create plot\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.barplot(\n",
    "        x=categories, \n",
    "        y=mean_values, \n",
    "        palette=\"muted\"\n",
    "    )\n",
    "\n",
    "    # Add error bars manually\n",
    "    plt.errorbar(\n",
    "        x=range(len(categories)), \n",
    "        y=mean_values, \n",
    "        yerr=std_values, \n",
    "        fmt='none', \n",
    "        c='black', \n",
    "        capsize=5\n",
    "    )\n",
    "\n",
    "    plt.title(f\"Mean {feature} per Category (Training Data)\", fontsize=16)\n",
    "    plt.xlabel(\"Category\", fontsize=14)\n",
    "    plt.ylabel(f\"Mean {feature} Value\", fontsize=14)\n",
    "    plt.xticks(rotation=45, ha=\"right\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"/Users/derre/Documents/workspace/smell-net/data_stats/feature_distributions_category/{feature}_mean_per_category.png\", dpi=300)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "027ef795",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "for feature in sensor_columns:\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    # Plot one KDE per category\n",
    "    for category in aggregated_training['category'].dropna().unique():\n",
    "        subset = aggregated_training[aggregated_training['category'] == category]\n",
    "        sns.kdeplot(\n",
    "            subset[feature], \n",
    "            label=category, \n",
    "            fill=True, \n",
    "            alpha=0.3\n",
    "        )\n",
    "    \n",
    "    plt.title(f\"Training Data: {feature} Distribution by Category\", fontsize=16)\n",
    "    plt.xlabel(feature, fontsize=14)\n",
    "    plt.ylabel(\"Density\", fontsize=14)\n",
    "    plt.legend(title=\"Category\", fontsize=10)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"/home/dewei/workspace/smell-net/data_stats/feature_distributions_category/{feature}_kde_by_category.png\", dpi=300)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aeaddf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_files = [\"angelica_test_0\", \"mint_test_0\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "24d81ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_files = [\"angelica_test_0\", \"mint_test_0\"]\n",
    "plot_columns = [\"NO2\"]\n",
    "\n",
    "for file_id in sampled_files:\n",
    "    df = aggregated_testing[aggregated_testing['file_id'] == file_id].copy()\n",
    "\n",
    "    for col in plot_columns:\n",
    "        # Wider figure for better aspect ratio\n",
    "        fig, ax = plt.subplots(figsize=(8, 4))\n",
    "\n",
    "        ax.plot(df['time_step'], df[col], color='steelblue')\n",
    "\n",
    "        # Titles and labels\n",
    "        ax.set_title(f\"NO2 over Time\", fontsize=22, fontweight='bold')\n",
    "        ax.set_xlabel(\"Time Step\", fontsize=20)\n",
    "        ax.set_ylabel(col, fontsize=20)\n",
    "        ax.tick_params(axis='both', which='major', labelsize=16)\n",
    "        ax.grid(True)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f\"/home/dewei/workspace/smell-net/data_stats/time_series_analysis/{file_id}_{col}_timeseries.png\", dpi=300)\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61590319",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Compute correlation matrix\n",
    "correlation_matrix = aggregated_training[sensor_columns].corr()\n",
    "\n",
    "# 2. Plot the correlation matrix\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(correlation_matrix, \n",
    "            annot=True, \n",
    "            fmt=\".2f\", \n",
    "            cmap=\"coolwarm\", \n",
    "            vmin=-1, vmax=1,\n",
    "            square=True,\n",
    "            cbar_kws={\"shrink\": 0.8})\n",
    "\n",
    "plt.title(\"Sensor Feature Correlation Matrix\", fontsize=16)\n",
    "plt.xticks(rotation=45)\n",
    "plt.yticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"/Users/derre/Documents/workspace/smell-net/data_stats/feature_correlation.png\", dpi=300)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "68176c62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained variance ratios: [0.39145314 0.34491947]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# === Prepare Sensor Data ===\n",
    "X_raw = aggregated_training[sensor_columns]\n",
    "y_category = aggregated_training['category']\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_raw)\n",
    "\n",
    "# === PCA Transformation ===\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "explained_var = pca.explained_variance_ratio_\n",
    "print(f\"Explained variance ratios: {explained_var}\")\n",
    "\n",
    "# === Create DataFrame for Visualization ===\n",
    "pca_df = pd.DataFrame({\n",
    "    'PC1': X_pca[:, 0],\n",
    "    'PC2': X_pca[:, 1],\n",
    "    'Category': y_category\n",
    "})\n",
    "\n",
    "# === Plotting ===\n",
    "sns.set(style=\"whitegrid\", context=\"notebook\")  # 'notebook' = larger fonts\n",
    "custom_palette = [\"#1f77b4\", \"#ff7f0e\", \"#2ca02c\", \"#d62728\", \"#9467bd\"]\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "plot = sns.scatterplot(\n",
    "    data=pca_df,\n",
    "    x='PC1', y='PC2',\n",
    "    hue='Category',\n",
    "    palette=custom_palette,\n",
    "    s=8,             # larger dots\n",
    "    alpha=0.6,\n",
    "    linewidth=0\n",
    ")\n",
    "\n",
    "# Axis labels with explained variance\n",
    "plt.xlabel(f\"PC1 ({explained_var[0]*100:.1f}% variance)\", fontsize=25)\n",
    "plt.ylabel(f\"PC2 ({explained_var[1]*100:.1f}% variance)\", fontsize=25)\n",
    "plt.title(\"PCA of Sensor Data\", fontsize=33, fontweight='bold')\n",
    "\n",
    "# Tick label fonts\n",
    "plt.xticks(fontsize=18)\n",
    "plt.yticks(fontsize=18)\n",
    "\n",
    "# Legend styling\n",
    "plt.legend(\n",
    "    title=\"Ingredient Category\",\n",
    "    title_fontsize=25,\n",
    "    fontsize=25,\n",
    "    bbox_to_anchor=(1.05, 1),\n",
    "    loc='upper left',\n",
    "    handletextpad=0.4,\n",
    "    borderaxespad=0.2,\n",
    "    labelspacing=0.8,\n",
    "    handlelength=2.5,\n",
    "    markerscale=5   # Increase dot size in legend\n",
    ")\n",
    "\n",
    "# Save figure\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"/home/dewei/workspace/smell-net/data_stats/PCA_sensor_data_category.png\", dpi=300)\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0676295",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature contributions (loadings) for PC1 and PC2\n",
    "loadings = pd.DataFrame(pca.components_.T,  # transpose to get features as rows\n",
    "                        columns=['PC1', 'PC2'],\n",
    "                        index=sensor_columns)\n",
    "\n",
    "# Compute magnitude of contribution (Euclidean norm)\n",
    "loadings['Magnitude'] = (loadings[['PC1', 'PC2']]**2).sum(axis=1)**0.5\n",
    "\n",
    "# Sort features by magnitude\n",
    "top_features = loadings.sort_values('Magnitude', ascending=False)\n",
    "print(\"\\nTop contributing features:\")\n",
    "print(top_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4bb42047",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Seaborn style for large, clear visuals\n",
    "sns.set(style=\"whitegrid\", context=\"notebook\", font_scale=1.4)\n",
    "\n",
    "# Output directory\n",
    "output_dir = \"/home/dewei/workspace/smell-net/data_stats/pca_by_category_colored\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Iterate over each category\n",
    "for category in aggregated_training['category'].unique():\n",
    "    group_df = aggregated_training[aggregated_training['category'] == category]\n",
    "    X = group_df[sensor_columns]\n",
    "\n",
    "    # Standardize\n",
    "    X_scaled = StandardScaler().fit_transform(X)\n",
    "\n",
    "    # PCA\n",
    "    pca = PCA(n_components=2)\n",
    "    X_pca = pca.fit_transform(X_scaled)\n",
    "    explained_var = pca.explained_variance_ratio_\n",
    "\n",
    "    # Build PCA DataFrame\n",
    "    pca_df = pd.DataFrame({\n",
    "        'PC1': X_pca[:, 0],\n",
    "        'PC2': X_pca[:, 1],\n",
    "        'Ingredient': group_df['ingredient'].values\n",
    "    })\n",
    "\n",
    "    # Create figure\n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "    # Scatter plot with larger, semi-transparent dots\n",
    "    sns.scatterplot(\n",
    "        data=pca_df,\n",
    "        x='PC1', y='PC2',\n",
    "        hue='Ingredient',\n",
    "        palette='tab20',\n",
    "        s=8,\n",
    "        alpha=0.7,\n",
    "        linewidth=0,\n",
    "        ax=ax\n",
    "    )\n",
    "\n",
    "    # Axis and title styling\n",
    "    ax.set_title(f\"{category} PCA\", fontsize=33, fontweight='bold')\n",
    "    ax.set_xlabel(f\"PC1 ({explained_var[0]*100:.1f}% variance)\", fontsize=25)\n",
    "    ax.set_ylabel(f\"PC2 ({explained_var[1]*100:.1f}% variance)\", fontsize=25)\n",
    "    ax.tick_params(axis='both', labelsize=16)\n",
    "\n",
    "    # Adjust legend: bold text and bigger markers\n",
    "    plt.legend(\n",
    "        title=\"Ingredient\",\n",
    "        title_fontsize=25,\n",
    "        fontsize=25,\n",
    "        bbox_to_anchor=(1.05, 1),\n",
    "        loc='upper left',\n",
    "        handletextpad=0.4,\n",
    "        borderaxespad=0.2,\n",
    "        labelspacing=0.8,\n",
    "        handlelength=2.5,\n",
    "        markerscale=5   # Increase dot size in legend\n",
    "    )\n",
    "\n",
    "    # Save plot\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{output_dir}/PCA_{category.replace(' ', '_')}_by_ingredient.png\", dpi=300)\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd6b7162",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set up the grid for subplots\n",
    "categories = aggregated_training['category'].unique()\n",
    "n_categories = len(categories)\n",
    "\n",
    "n_cols = 5  # You can change this\n",
    "n_rows = (n_categories + n_cols - 1) // n_cols  # Ceiling division\n",
    "\n",
    "plt.figure(figsize=(4 * n_cols, 4 * n_rows))\n",
    "\n",
    "for i, category in enumerate(categories):\n",
    "    plt.subplot(n_rows, n_cols, i + 1)\n",
    "    \n",
    "    # Select data for this category\n",
    "    group_df = aggregated_training[aggregated_training['category'] == category]\n",
    "    X = group_df[sensor_columns]\n",
    "    \n",
    "    # Standardize\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    \n",
    "    # PCA\n",
    "    pca = PCA(n_components=2)\n",
    "    X_pca = pca.fit_transform(X_scaled)\n",
    "    explained = pca.explained_variance_ratio_\n",
    "    \n",
    "    # Scatter plot\n",
    "    plt.scatter(X_pca[:, 0], X_pca[:, 1], s=5, alpha=0.6)\n",
    "    \n",
    "    # Title with explained variance\n",
    "    plt.title(f\"{category}\\n({explained[0]*100:.1f}%, {explained[1]*100:.1f}%)\", fontsize=10)\n",
    "    \n",
    "    # Remove ticks but keep axis labels\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.xlabel('PC1', fontsize=8)\n",
    "    plt.ylabel('PC2', fontsize=8)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "976827df",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_category_rows = aggregated_training[aggregated_training['category'].isna()]\n",
    "\n",
    "# Display them\n",
    "print(missing_category_rows)\n",
    "\n",
    "# Optional: check how many\n",
    "print(f\"Number of rows with missing category: {len(missing_category_rows)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1a4896e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['Cashew', 'Peanuts', 'Pecans', 'Walnuts', 'Pili Nut']\n",
    "cos_similarities = [0.7176, 0.5056, 0.4912, 0.3945, 0.3466]\n",
    "colors = ['midnightblue'] + ['royalblue'] * 4\n",
    "\n",
    "plt.figure(figsize=(6, 4.5))  # Match aspect ratio to 4:3\n",
    "\n",
    "bars = plt.bar(labels, cos_similarities, color=colors, edgecolor='black', linewidth=1.2)\n",
    "\n",
    "for bar, sim in zip(bars, cos_similarities):\n",
    "    plt.text(bar.get_x() + bar.get_width() / 2, bar.get_height() + 0.015, \n",
    "             f\"{sim:.2f}\", ha='center', va='bottom', fontsize=14)\n",
    "\n",
    "plt.title(\"Top-5 Predicted Ingredients\", fontsize=20, fontweight='bold')\n",
    "plt.ylabel(\"Cosine Similarity\", fontsize=20)\n",
    "plt.xticks(fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "plt.ylim(0, max(cos_similarities) + 0.1)\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.5)\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(\"model_predictions.png\", dpi=300)\n",
    "plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
